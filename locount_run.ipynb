{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's take a look at the dataset image\n",
    "# import mmcv\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# img = mmcv.imread('data/coco/Locount_ImagesTest/000005.jpg')\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.imshow(mmcv.bgr2rgb(img))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "cfg = Config.fromfile('./configs/cascade_rcnn/cascade-rcnn_r50_fpn_1x_coco_locount.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: ./configs/cascade_rcnn/cascade-rcnn_r50_fpn_1x_coco_locount.py): {'model': {'type': 'CascadeRCNN', 'data_preprocessor': {'type': 'DetDataPreprocessor', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'bgr_to_rgb': True, 'pad_size_divisor': 32}, 'backbone': {'type': 'ResNet', 'depth': 50, 'num_stages': 4, 'out_indices': (0, 1, 2, 3), 'frozen_stages': 1, 'norm_cfg': {'type': 'BN', 'requires_grad': True}, 'norm_eval': True, 'style': 'pytorch', 'init_cfg': {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}}, 'neck': {'type': 'FPN', 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256, 'num_outs': 5}, 'rpn_head': {'type': 'RPNHead', 'in_channels': 256, 'feat_channels': 256, 'anchor_generator': {'type': 'AnchorGenerator', 'scales': [8], 'ratios': [0.5, 1.0, 2.0], 'strides': [4, 8, 16, 32, 64]}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [1.0, 1.0, 1.0, 1.0]}, 'loss_cls': {'type': 'CrossEntropyLoss', 'use_sigmoid': True, 'loss_weight': 1.0}, 'loss_bbox': {'type': 'SmoothL1Loss', 'beta': 0.1111111111111111, 'loss_weight': 1.0}}, 'roi_head': {'type': 'CascadeRoIHead', 'num_stages': 3, 'stage_loss_weights': [1, 0.5, 0.25], 'bbox_roi_extractor': {'type': 'SingleRoIExtractor', 'roi_layer': {'type': 'RoIAlign', 'output_size': 7, 'sampling_ratio': 0}, 'out_channels': 256, 'featmap_strides': [4, 8, 16, 32]}, 'bbox_head': [{'type': 'Shared2FCBBoxHead', 'in_channels': 256, 'fc_out_channels': 1024, 'roi_feat_size': 7, 'num_classes': 140, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.1, 0.1, 0.2, 0.2]}, 'reg_class_agnostic': True, 'loss_cls': {'type': 'CrossEntropyLoss', 'use_sigmoid': False, 'loss_weight': 1.0}, 'loss_bbox': {'type': 'SmoothL1Loss', 'beta': 1.0, 'loss_weight': 1.0}}, {'type': 'Shared2FCBBoxHead', 'in_channels': 256, 'fc_out_channels': 1024, 'roi_feat_size': 7, 'num_classes': 140, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.05, 0.05, 0.1, 0.1]}, 'reg_class_agnostic': True, 'loss_cls': {'type': 'CrossEntropyLoss', 'use_sigmoid': False, 'loss_weight': 1.0}, 'loss_bbox': {'type': 'SmoothL1Loss', 'beta': 1.0, 'loss_weight': 1.0}}, {'type': 'Shared2FCBBoxHead', 'in_channels': 256, 'fc_out_channels': 1024, 'roi_feat_size': 7, 'num_classes': 140, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.033, 0.033, 0.067, 0.067]}, 'reg_class_agnostic': True, 'loss_cls': {'type': 'CrossEntropyLoss', 'use_sigmoid': False, 'loss_weight': 1.0}, 'loss_bbox': {'type': 'SmoothL1Loss', 'beta': 1.0, 'loss_weight': 1.0}}]}, 'train_cfg': {'rpn': {'assigner': {'type': 'MaxIoUAssigner', 'pos_iou_thr': 0.7, 'neg_iou_thr': 0.3, 'min_pos_iou': 0.3, 'match_low_quality': True, 'ignore_iof_thr': -1}, 'sampler': {'type': 'RandomSampler', 'num': 256, 'pos_fraction': 0.5, 'neg_pos_ub': -1, 'add_gt_as_proposals': False}, 'allowed_border': 0, 'pos_weight': -1, 'debug': False}, 'rpn_proposal': {'nms_pre': 2000, 'max_per_img': 2000, 'nms': {'type': 'nms', 'iou_threshold': 0.7}, 'min_bbox_size': 0}, 'rcnn': [{'assigner': {'type': 'MaxIoUAssigner', 'pos_iou_thr': 0.5, 'neg_iou_thr': 0.5, 'min_pos_iou': 0.5, 'match_low_quality': False, 'ignore_iof_thr': -1}, 'sampler': {'type': 'RandomSampler', 'num': 512, 'pos_fraction': 0.25, 'neg_pos_ub': -1, 'add_gt_as_proposals': True}, 'pos_weight': -1, 'debug': False}, {'assigner': {'type': 'MaxIoUAssigner', 'pos_iou_thr': 0.6, 'neg_iou_thr': 0.6, 'min_pos_iou': 0.6, 'match_low_quality': False, 'ignore_iof_thr': -1}, 'sampler': {'type': 'RandomSampler', 'num': 512, 'pos_fraction': 0.25, 'neg_pos_ub': -1, 'add_gt_as_proposals': True}, 'pos_weight': -1, 'debug': False}, {'assigner': {'type': 'MaxIoUAssigner', 'pos_iou_thr': 0.7, 'neg_iou_thr': 0.7, 'min_pos_iou': 0.7, 'match_low_quality': False, 'ignore_iof_thr': -1}, 'sampler': {'type': 'RandomSampler', 'num': 512, 'pos_fraction': 0.25, 'neg_pos_ub': -1, 'add_gt_as_proposals': True}, 'pos_weight': -1, 'debug': False}]}, 'test_cfg': {'rpn': {'nms_pre': 1000, 'max_per_img': 1000, 'nms': {'type': 'nms', 'iou_threshold': 0.7}, 'min_bbox_size': 0}, 'rcnn': {'score_thr': 0.05, 'nms': {'type': 'nms', 'iou_threshold': 0.5}, 'max_per_img': 100}}}, 'dataset_type': 'CocoDataset', 'data_root': 'data/coco/', 'backend_args': None, 'train_pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': (1333, 800), 'keep_ratio': True}, {'type': 'RandomFlip', 'prob': 0.5}, {'type': 'PackDetInputs'}], 'test_pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': (1333, 800), 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor')}], 'train_dataloader': {'batch_size': 2, 'num_workers': 2, 'persistent_workers': True, 'sampler': {'type': 'DefaultSampler', 'shuffle': True}, 'batch_sampler': {'type': 'AspectRatioBatchSampler'}, 'dataset': {'type': 'CocoDataset', 'data_root': 'data/coco/', 'ann_file': 'annotations/instances_train2017.json', 'data_prefix': {'img': 'train2017/'}, 'filter_cfg': {'filter_empty_gt': True, 'min_size': 32}, 'pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': (1333, 800), 'keep_ratio': True}, {'type': 'RandomFlip', 'prob': 0.5}, {'type': 'PackDetInputs'}], 'backend_args': None}}, 'val_dataloader': {'batch_size': 1, 'num_workers': 2, 'persistent_workers': True, 'drop_last': False, 'sampler': {'type': 'DefaultSampler', 'shuffle': False}, 'dataset': {'type': 'CocoDataset', 'data_root': 'data/coco/', 'ann_file': 'annotations/instances_val2017.json', 'data_prefix': {'img': 'val2017/'}, 'test_mode': True, 'pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': (1333, 800), 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor')}], 'backend_args': None}}, 'test_dataloader': {'batch_size': 1, 'num_workers': 2, 'persistent_workers': True, 'drop_last': False, 'sampler': {'type': 'DefaultSampler', 'shuffle': False}, 'dataset': {'type': 'CocoDataset', 'data_root': 'data/coco/', 'ann_file': 'annotations/instances_val2017.json', 'data_prefix': {'img': 'val2017/'}, 'test_mode': True, 'pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': (1333, 800), 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor')}], 'backend_args': None}}, 'val_evaluator': {'type': 'CocoMetric', 'ann_file': 'data/coco/annotations/instances_val2017.json', 'metric': 'bbox', 'format_only': False, 'backend_args': None}, 'test_evaluator': {'type': 'CocoMetric', 'ann_file': 'data/coco/annotations/instances_val2017.json', 'metric': 'bbox', 'format_only': False, 'backend_args': None}, 'train_cfg': {'type': 'EpochBasedTrainLoop', 'max_epochs': 12, 'val_interval': 1}, 'val_cfg': {'type': 'ValLoop'}, 'test_cfg': {'type': 'TestLoop'}, 'param_scheduler': [{'type': 'LinearLR', 'start_factor': 0.001, 'by_epoch': False, 'begin': 0, 'end': 500}, {'type': 'MultiStepLR', 'begin': 0, 'end': 12, 'by_epoch': True, 'milestones': [8, 11], 'gamma': 0.1}], 'optim_wrapper': {'type': 'OptimWrapper', 'optimizer': {'type': 'SGD', 'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.0001}}, 'auto_scale_lr': {'enable': False, 'base_batch_size': 16}, 'default_scope': 'mmdet', 'default_hooks': {'timer': {'type': 'IterTimerHook'}, 'logger': {'type': 'LoggerHook', 'interval': 50}, 'param_scheduler': {'type': 'ParamSchedulerHook'}, 'checkpoint': {'type': 'CheckpointHook', 'interval': 1}, 'sampler_seed': {'type': 'DistSamplerSeedHook'}, 'visualization': {'type': 'DetVisualizationHook'}}, 'env_cfg': {'cudnn_benchmark': False, 'mp_cfg': {'mp_start_method': 'fork', 'opencv_num_threads': 0}, 'dist_cfg': {'backend': 'nccl'}}, 'vis_backends': [{'type': 'LocalVisBackend'}], 'visualizer': {'type': 'DetLocalVisualizer', 'vis_backends': [{'type': 'LocalVisBackend'}], 'name': 'visualizer'}, 'log_processor': {'type': 'LogProcessor', 'window_size': 50, 'by_epoch': True}, 'log_level': 'INFO', 'load_from': None, 'resume': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/openmmlab/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mmengine.runner import set_random_seed\n",
    "\n",
    "# Modify dataset classes and color\n",
    "cfg.metainfo = {\n",
    "    'classes': ('Thermos bottle', 'Soymilk', 'Baby slippers', 'Makeup tools', 'Adult milk powder', 'Red wine', 'Toothpaste', 'Pot shovel', 'Rubber ball', 'Rise', 'Stool', 'Vinegar', 'Children Socks', 'Shampoo', 'Cake', 'Pen', 'Flour', 'Sesame paste', 'Dried meat', 'Baby diapers', 'Jacket', 'Herbal tea', 'Mouth wash', 'Care Kit', 'Baby Toys', 'Quick-frozen Wonton', 'Quick-frozen Tangyuan', 'Electric Hot pot', 'Electric steaming pan', 'Electric kettle', 'Sports cup', 'Quick-frozen dumplings', 'Can', 'Air conditioner', 'Instant noodles', 'Baby washing and nursing supplie', 'Socket', 'Potato chips', 'Disposable bag', 'Adult shoes', 'Football', 'Hair drier', 'Chopping block', 'Lingerie', 'Mug', 'Soup ladle', 'Children hats', 'Lotus root flour', 'Fish tofu', 'Electric iron', 'Ice cream', 'Bath lotion', 'Juicer', 'Tea beverage', 'Dinner plate', 'Notebook', 'Facial Cleanser', 'Biscuits', 'Chewing gum', 'Mixed congee', 'Facial mask', 'Bowl', 'Soybean Milk machine', 'Men underwear', 'Dairy', 'Hair gel', 'Tea', 'Storage bottle', 'Spoon', 'Baby milk powder', 'Sauce', 'Electric fan', 'Dried beans', 'Disposable cups', 'Draw bar box', 'Cooking wine', 'Pencil case', 'Carbonated drinks', 'Adult Diapers', 'Soy sauce', 'Desk lamp', 'Electromagnetic furnace', 'Badminton', 'Coffee', 'Air conditioning fan', 'Tampon', 'Children Toys', 'Children underwear', 'Knives', 'Pasta', 'Microwave Oven', 'Hair conditioner', 'Ginger Tea', 'Baby Furniture', 'Forks', 'Pie', 'Television', 'Baby tableware', 'Skate', 'Oats', 'Cotton swab', 'Storage box', 'Noodle', 'Razor', 'Refrigerator', 'Toothbrush', 'Chocolates', 'Adult socks', 'Knapsack', 'Sour Plum Soup', 'Cutter', 'Band aid', 'Rice cooker', 'Cocktail', 'Skin care set', 'Walnut powder', 'Liquor and Spirits', 'Emulsion', 'Soap', 'Hair dye', 'Fresh-keeping film', 'Baby handkerchiefs ', 'Children shoes', 'Washing machine', 'Chopsticks', 'Guozhen', 'Trousers', 'Adult hat', 'Trash', 'Bedding set', 'Basin', 'Electric frying pan', 'Food box', 'Dried fish', 'Baby carriage', 'Hot strips', 'Basketball', 'Comb', 'Coat hanger')\n",
    "}\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.data_root = 'data/coco'\n",
    "\n",
    "cfg.train_dataloader.dataset.ann_file = 'annotations/annotation_train.json'\n",
    "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
    "cfg.train_dataloader.dataset.data_prefix.img = 'Locount_ImagesTrain'\n",
    "cfg.train_dataloader.dataset.metainfo = cfg.metainfo\n",
    "\n",
    "cfg.val_dataloader.dataset.ann_file = 'annotations/annotation_test.json'\n",
    "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
    "cfg.val_dataloader.dataset.data_prefix.img = 'Locount_ImagesTest'\n",
    "cfg.val_dataloader.dataset.metainfo = cfg.metainfo\n",
    "\n",
    "cfg.test_dataloader = cfg.val_dataloader\n",
    "\n",
    "# Modify metric config\n",
    "cfg.val_evaluator.ann_file = cfg.data_root+'/'+'annotations/annotation_test.json'\n",
    "cfg.test_evaluator = cfg.val_evaluator\n",
    "\n",
    "# Modify num classes of the model in box head and mask head\n",
    "# cfg.model.roi_head.bbox_head.num_classes = 140\n",
    "# cfg.model.roi_head.mask_head.num_classes = 140\n",
    "\n",
    "# We can still the pre-trained Mask RCNN model to obtain a higher performance\n",
    "# cfg.load_from = 'checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './tutorial_exps'\n",
    "\n",
    "\n",
    "# We can set the evaluation interval to reduce the evaluation times\n",
    "cfg.train_cfg.val_interval = 3\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.default_hooks.checkpoint.interval = 3\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.optim_wrapper.optimizer.lr = 0.02 / 8\n",
    "cfg.default_hooks.logger.interval = 10\n",
    "\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "# cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "\n",
    "# We can also use tensorboard to log the training process\n",
    "cfg.visualizer.vis_backends.append({\"type\":'TensorboardVisBackend'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/16 21:04:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: darwin\n",
      "    Python: 3.8.17 (default, Jul  5 2023, 16:18:40) [Clang 14.0.6 ]\n",
      "    CUDA available: False\n",
      "    numpy_random_seed: 209652396\n",
      "    GCC: Apple clang version 14.0.3 (clang-1403.0.22.14.1)\n",
      "    PyTorch: 1.13.1\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 4.2\n",
      "  - C++ Version: 201402\n",
      "  - clang 14.0.6\n",
      "  - OpenMP 201811\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: NO AVX\n",
      "  - Build settings: BLAS_INFO=open, BUILD_TYPE=Release, CXX_COMPILER=/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_9d63z49rj_/croot/pytorch_1681837279022/_build_env/bin/x86_64-apple-darwin13.4.0-clang++, CXX_FLAGS=-march=core2 -mtune=haswell -mssse3 -ftree-vectorize -fPIC -fPIE -fstack-protector-strong -O2 -pipe -stdlib=libc++  -fmessage-length=0 -isystem /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_9d63z49rj_/croot/pytorch_1681837279022/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeh/include -fdebug-prefix-map=/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_9d63z49rj_/croot/pytorch_1681837279022/work=/usr/local/src/conda/pytorch-1.13.1 -fdebug-prefix-map=/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_9d63z49rj_/croot/pytorch_1681837279022/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeh=/usr/local/src/conda-prefix -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp=libomp -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wvla-extension -Wno-range-loop-analysis -Wno-pass-failed -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -Wconstant-conversion -Wno-invalid-partial-specialization -Wno-typedef-redefinition -Wno-unused-private-field -Wno-inconsistent-missing-override -Wno-c++14-extensions -Wno-constexpr-not-const -Wno-missing-braces -Wunused-lambda-capture -Wunused-local-typedef -Qunused-arguments -fcolor-diagnostics -fdiagnostics-color=always -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-unused-private-field -Wno-missing-braces -Wno-c++14-extensions -Wno-constexpr-not-const, LAPACK_INFO=open, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=0, USE_CUDNN=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2a0\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.8.2\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 209652396\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <870081F6-12FD-3CEA-BC5C-30F4764F2A98> /opt/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <F2FE5CF8-5B5B-3FAD-ADF8-C77D90F49FC9> /opt/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/16 21:04:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "model = dict(\n",
      "    type='CascadeRCNN',\n",
      "    data_preprocessor=dict(\n",
      "        type='DetDataPreprocessor',\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        bgr_to_rgb=True,\n",
      "        pad_size_divisor=32),\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(\n",
      "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='CascadeRoIHead',\n",
      "        num_stages=3,\n",
      "        stage_loss_weights=[\n",
      "            1,\n",
      "            0.5,\n",
      "            0.25,\n",
      "        ],\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ]),\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=140,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                        0.2,\n",
      "                        0.2,\n",
      "                    ]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
      "                               loss_weight=1.0)),\n",
      "            dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=140,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.05,\n",
      "                        0.05,\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                    ]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
      "                               loss_weight=1.0)),\n",
      "            dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=140,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.033,\n",
      "                        0.033,\n",
      "                        0.067,\n",
      "                        0.067,\n",
      "                    ]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
      "                               loss_weight=1.0)),\n",
      "        ]),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=0,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=2000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    min_pos_iou=0.6,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    min_pos_iou=0.7,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "        ]),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100)))\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = 'data/coco'\n",
      "backend_args = None\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile', backend_args=None),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='Resize', scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), keep_ratio=True),\n",
      "    dict(type='RandomFlip', prob=0.5),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile', backend_args=None),\n",
      "    dict(type='Resize', scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), keep_ratio=True),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='PackDetInputs',\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        )),\n",
      "]\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    dataset=dict(\n",
      "        type='CocoDataset',\n",
      "        data_root='data/coco',\n",
      "        ann_file='annotations/annotation_train.json',\n",
      "        data_prefix=dict(img='Locount_ImagesTrain'),\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', backend_args=None),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='Resize', scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), keep_ratio=True),\n",
      "            dict(type='RandomFlip', prob=0.5),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        backend_args=None,\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Thermos bottle',\n",
      "                'Soymilk',\n",
      "                'Baby slippers',\n",
      "                'Makeup tools',\n",
      "                'Adult milk powder',\n",
      "                'Red wine',\n",
      "                'Toothpaste',\n",
      "                'Pot shovel',\n",
      "                'Rubber ball',\n",
      "                'Rise',\n",
      "                'Stool',\n",
      "                'Vinegar',\n",
      "                'Children Socks',\n",
      "                'Shampoo',\n",
      "                'Cake',\n",
      "                'Pen',\n",
      "                'Flour',\n",
      "                'Sesame paste',\n",
      "                'Dried meat',\n",
      "                'Baby diapers',\n",
      "                'Jacket',\n",
      "                'Herbal tea',\n",
      "                'Mouth wash',\n",
      "                'Care Kit',\n",
      "                'Baby Toys',\n",
      "                'Quick-frozen Wonton',\n",
      "                'Quick-frozen Tangyuan',\n",
      "                'Electric Hot pot',\n",
      "                'Electric steaming pan',\n",
      "                'Electric kettle',\n",
      "                'Sports cup',\n",
      "                'Quick-frozen dumplings',\n",
      "                'Can',\n",
      "                'Air conditioner',\n",
      "                'Instant noodles',\n",
      "                'Baby washing and nursing supplie',\n",
      "                'Socket',\n",
      "                'Potato chips',\n",
      "                'Disposable bag',\n",
      "                'Adult shoes',\n",
      "                'Football',\n",
      "                'Hair drier',\n",
      "                'Chopping block',\n",
      "                'Lingerie',\n",
      "                'Mug',\n",
      "                'Soup ladle',\n",
      "                'Children hats',\n",
      "                'Lotus root flour',\n",
      "                'Fish tofu',\n",
      "                'Electric iron',\n",
      "                'Ice cream',\n",
      "                'Bath lotion',\n",
      "                'Juicer',\n",
      "                'Tea beverage',\n",
      "                'Dinner plate',\n",
      "                'Notebook',\n",
      "                'Facial Cleanser',\n",
      "                'Biscuits',\n",
      "                'Chewing gum',\n",
      "                'Mixed congee',\n",
      "                'Facial mask',\n",
      "                'Bowl',\n",
      "                'Soybean Milk machine',\n",
      "                'Men underwear',\n",
      "                'Dairy',\n",
      "                'Hair gel',\n",
      "                'Tea',\n",
      "                'Storage bottle',\n",
      "                'Spoon',\n",
      "                'Baby milk powder',\n",
      "                'Sauce',\n",
      "                'Electric fan',\n",
      "                'Dried beans',\n",
      "                'Disposable cups',\n",
      "                'Draw bar box',\n",
      "                'Cooking wine',\n",
      "                'Pencil case',\n",
      "                'Carbonated drinks',\n",
      "                'Adult Diapers',\n",
      "                'Soy sauce',\n",
      "                'Desk lamp',\n",
      "                'Electromagnetic furnace',\n",
      "                'Badminton',\n",
      "                'Coffee',\n",
      "                'Air conditioning fan',\n",
      "                'Tampon',\n",
      "                'Children Toys',\n",
      "                'Children underwear',\n",
      "                'Knives',\n",
      "                'Pasta',\n",
      "                'Microwave Oven',\n",
      "                'Hair conditioner',\n",
      "                'Ginger Tea',\n",
      "                'Baby Furniture',\n",
      "                'Forks',\n",
      "                'Pie',\n",
      "                'Television',\n",
      "                'Baby tableware',\n",
      "                'Skate',\n",
      "                'Oats',\n",
      "                'Cotton swab',\n",
      "                'Storage box',\n",
      "                'Noodle',\n",
      "                'Razor',\n",
      "                'Refrigerator',\n",
      "                'Toothbrush',\n",
      "                'Chocolates',\n",
      "                'Adult socks',\n",
      "                'Knapsack',\n",
      "                'Sour Plum Soup',\n",
      "                'Cutter',\n",
      "                'Band aid',\n",
      "                'Rice cooker',\n",
      "                'Cocktail',\n",
      "                'Skin care set',\n",
      "                'Walnut powder',\n",
      "                'Liquor and Spirits',\n",
      "                'Emulsion',\n",
      "                'Soap',\n",
      "                'Hair dye',\n",
      "                'Fresh-keeping film',\n",
      "                'Baby handkerchiefs ',\n",
      "                'Children shoes',\n",
      "                'Washing machine',\n",
      "                'Chopsticks',\n",
      "                'Guozhen',\n",
      "                'Trousers',\n",
      "                'Adult hat',\n",
      "                'Trash',\n",
      "                'Bedding set',\n",
      "                'Basin',\n",
      "                'Electric frying pan',\n",
      "                'Food box',\n",
      "                'Dried fish',\n",
      "                'Baby carriage',\n",
      "                'Hot strips',\n",
      "                'Basketball',\n",
      "                'Comb',\n",
      "                'Coat hanger',\n",
      "            ))))\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    drop_last=False,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
      "    dataset=dict(\n",
      "        type='CocoDataset',\n",
      "        data_root='data/coco',\n",
      "        ann_file='annotations/annotation_test.json',\n",
      "        data_prefix=dict(img='Locount_ImagesTest'),\n",
      "        test_mode=True,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', backend_args=None),\n",
      "            dict(type='Resize', scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), keep_ratio=True),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='PackDetInputs',\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                )),\n",
      "        ],\n",
      "        backend_args=None,\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Thermos bottle',\n",
      "                'Soymilk',\n",
      "                'Baby slippers',\n",
      "                'Makeup tools',\n",
      "                'Adult milk powder',\n",
      "                'Red wine',\n",
      "                'Toothpaste',\n",
      "                'Pot shovel',\n",
      "                'Rubber ball',\n",
      "                'Rise',\n",
      "                'Stool',\n",
      "                'Vinegar',\n",
      "                'Children Socks',\n",
      "                'Shampoo',\n",
      "                'Cake',\n",
      "                'Pen',\n",
      "                'Flour',\n",
      "                'Sesame paste',\n",
      "                'Dried meat',\n",
      "                'Baby diapers',\n",
      "                'Jacket',\n",
      "                'Herbal tea',\n",
      "                'Mouth wash',\n",
      "                'Care Kit',\n",
      "                'Baby Toys',\n",
      "                'Quick-frozen Wonton',\n",
      "                'Quick-frozen Tangyuan',\n",
      "                'Electric Hot pot',\n",
      "                'Electric steaming pan',\n",
      "                'Electric kettle',\n",
      "                'Sports cup',\n",
      "                'Quick-frozen dumplings',\n",
      "                'Can',\n",
      "                'Air conditioner',\n",
      "                'Instant noodles',\n",
      "                'Baby washing and nursing supplie',\n",
      "                'Socket',\n",
      "                'Potato chips',\n",
      "                'Disposable bag',\n",
      "                'Adult shoes',\n",
      "                'Football',\n",
      "                'Hair drier',\n",
      "                'Chopping block',\n",
      "                'Lingerie',\n",
      "                'Mug',\n",
      "                'Soup ladle',\n",
      "                'Children hats',\n",
      "                'Lotus root flour',\n",
      "                'Fish tofu',\n",
      "                'Electric iron',\n",
      "                'Ice cream',\n",
      "                'Bath lotion',\n",
      "                'Juicer',\n",
      "                'Tea beverage',\n",
      "                'Dinner plate',\n",
      "                'Notebook',\n",
      "                'Facial Cleanser',\n",
      "                'Biscuits',\n",
      "                'Chewing gum',\n",
      "                'Mixed congee',\n",
      "                'Facial mask',\n",
      "                'Bowl',\n",
      "                'Soybean Milk machine',\n",
      "                'Men underwear',\n",
      "                'Dairy',\n",
      "                'Hair gel',\n",
      "                'Tea',\n",
      "                'Storage bottle',\n",
      "                'Spoon',\n",
      "                'Baby milk powder',\n",
      "                'Sauce',\n",
      "                'Electric fan',\n",
      "                'Dried beans',\n",
      "                'Disposable cups',\n",
      "                'Draw bar box',\n",
      "                'Cooking wine',\n",
      "                'Pencil case',\n",
      "                'Carbonated drinks',\n",
      "                'Adult Diapers',\n",
      "                'Soy sauce',\n",
      "                'Desk lamp',\n",
      "                'Electromagnetic furnace',\n",
      "                'Badminton',\n",
      "                'Coffee',\n",
      "                'Air conditioning fan',\n",
      "                'Tampon',\n",
      "                'Children Toys',\n",
      "                'Children underwear',\n",
      "                'Knives',\n",
      "                'Pasta',\n",
      "                'Microwave Oven',\n",
      "                'Hair conditioner',\n",
      "                'Ginger Tea',\n",
      "                'Baby Furniture',\n",
      "                'Forks',\n",
      "                'Pie',\n",
      "                'Television',\n",
      "                'Baby tableware',\n",
      "                'Skate',\n",
      "                'Oats',\n",
      "                'Cotton swab',\n",
      "                'Storage box',\n",
      "                'Noodle',\n",
      "                'Razor',\n",
      "                'Refrigerator',\n",
      "                'Toothbrush',\n",
      "                'Chocolates',\n",
      "                'Adult socks',\n",
      "                'Knapsack',\n",
      "                'Sour Plum Soup',\n",
      "                'Cutter',\n",
      "                'Band aid',\n",
      "                'Rice cooker',\n",
      "                'Cocktail',\n",
      "                'Skin care set',\n",
      "                'Walnut powder',\n",
      "                'Liquor and Spirits',\n",
      "                'Emulsion',\n",
      "                'Soap',\n",
      "                'Hair dye',\n",
      "                'Fresh-keeping film',\n",
      "                'Baby handkerchiefs ',\n",
      "                'Children shoes',\n",
      "                'Washing machine',\n",
      "                'Chopsticks',\n",
      "                'Guozhen',\n",
      "                'Trousers',\n",
      "                'Adult hat',\n",
      "                'Trash',\n",
      "                'Bedding set',\n",
      "                'Basin',\n",
      "                'Electric frying pan',\n",
      "                'Food box',\n",
      "                'Dried fish',\n",
      "                'Baby carriage',\n",
      "                'Hot strips',\n",
      "                'Basketball',\n",
      "                'Comb',\n",
      "                'Coat hanger',\n",
      "            ))))\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    drop_last=False,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
      "    dataset=dict(\n",
      "        type='CocoDataset',\n",
      "        data_root='data/coco',\n",
      "        ann_file='annotations/annotation_test.json',\n",
      "        data_prefix=dict(img='Locount_ImagesTest'),\n",
      "        test_mode=True,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', backend_args=None),\n",
      "            dict(type='Resize', scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), keep_ratio=True),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='PackDetInputs',\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                )),\n",
      "        ],\n",
      "        backend_args=None,\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Thermos bottle',\n",
      "                'Soymilk',\n",
      "                'Baby slippers',\n",
      "                'Makeup tools',\n",
      "                'Adult milk powder',\n",
      "                'Red wine',\n",
      "                'Toothpaste',\n",
      "                'Pot shovel',\n",
      "                'Rubber ball',\n",
      "                'Rise',\n",
      "                'Stool',\n",
      "                'Vinegar',\n",
      "                'Children Socks',\n",
      "                'Shampoo',\n",
      "                'Cake',\n",
      "                'Pen',\n",
      "                'Flour',\n",
      "                'Sesame paste',\n",
      "                'Dried meat',\n",
      "                'Baby diapers',\n",
      "                'Jacket',\n",
      "                'Herbal tea',\n",
      "                'Mouth wash',\n",
      "                'Care Kit',\n",
      "                'Baby Toys',\n",
      "                'Quick-frozen Wonton',\n",
      "                'Quick-frozen Tangyuan',\n",
      "                'Electric Hot pot',\n",
      "                'Electric steaming pan',\n",
      "                'Electric kettle',\n",
      "                'Sports cup',\n",
      "                'Quick-frozen dumplings',\n",
      "                'Can',\n",
      "                'Air conditioner',\n",
      "                'Instant noodles',\n",
      "                'Baby washing and nursing supplie',\n",
      "                'Socket',\n",
      "                'Potato chips',\n",
      "                'Disposable bag',\n",
      "                'Adult shoes',\n",
      "                'Football',\n",
      "                'Hair drier',\n",
      "                'Chopping block',\n",
      "                'Lingerie',\n",
      "                'Mug',\n",
      "                'Soup ladle',\n",
      "                'Children hats',\n",
      "                'Lotus root flour',\n",
      "                'Fish tofu',\n",
      "                'Electric iron',\n",
      "                'Ice cream',\n",
      "                'Bath lotion',\n",
      "                'Juicer',\n",
      "                'Tea beverage',\n",
      "                'Dinner plate',\n",
      "                'Notebook',\n",
      "                'Facial Cleanser',\n",
      "                'Biscuits',\n",
      "                'Chewing gum',\n",
      "                'Mixed congee',\n",
      "                'Facial mask',\n",
      "                'Bowl',\n",
      "                'Soybean Milk machine',\n",
      "                'Men underwear',\n",
      "                'Dairy',\n",
      "                'Hair gel',\n",
      "                'Tea',\n",
      "                'Storage bottle',\n",
      "                'Spoon',\n",
      "                'Baby milk powder',\n",
      "                'Sauce',\n",
      "                'Electric fan',\n",
      "                'Dried beans',\n",
      "                'Disposable cups',\n",
      "                'Draw bar box',\n",
      "                'Cooking wine',\n",
      "                'Pencil case',\n",
      "                'Carbonated drinks',\n",
      "                'Adult Diapers',\n",
      "                'Soy sauce',\n",
      "                'Desk lamp',\n",
      "                'Electromagnetic furnace',\n",
      "                'Badminton',\n",
      "                'Coffee',\n",
      "                'Air conditioning fan',\n",
      "                'Tampon',\n",
      "                'Children Toys',\n",
      "                'Children underwear',\n",
      "                'Knives',\n",
      "                'Pasta',\n",
      "                'Microwave Oven',\n",
      "                'Hair conditioner',\n",
      "                'Ginger Tea',\n",
      "                'Baby Furniture',\n",
      "                'Forks',\n",
      "                'Pie',\n",
      "                'Television',\n",
      "                'Baby tableware',\n",
      "                'Skate',\n",
      "                'Oats',\n",
      "                'Cotton swab',\n",
      "                'Storage box',\n",
      "                'Noodle',\n",
      "                'Razor',\n",
      "                'Refrigerator',\n",
      "                'Toothbrush',\n",
      "                'Chocolates',\n",
      "                'Adult socks',\n",
      "                'Knapsack',\n",
      "                'Sour Plum Soup',\n",
      "                'Cutter',\n",
      "                'Band aid',\n",
      "                'Rice cooker',\n",
      "                'Cocktail',\n",
      "                'Skin care set',\n",
      "                'Walnut powder',\n",
      "                'Liquor and Spirits',\n",
      "                'Emulsion',\n",
      "                'Soap',\n",
      "                'Hair dye',\n",
      "                'Fresh-keeping film',\n",
      "                'Baby handkerchiefs ',\n",
      "                'Children shoes',\n",
      "                'Washing machine',\n",
      "                'Chopsticks',\n",
      "                'Guozhen',\n",
      "                'Trousers',\n",
      "                'Adult hat',\n",
      "                'Trash',\n",
      "                'Bedding set',\n",
      "                'Basin',\n",
      "                'Electric frying pan',\n",
      "                'Food box',\n",
      "                'Dried fish',\n",
      "                'Baby carriage',\n",
      "                'Hot strips',\n",
      "                'Basketball',\n",
      "                'Comb',\n",
      "                'Coat hanger',\n",
      "            ))))\n",
      "val_evaluator = dict(\n",
      "    type='CocoMetric',\n",
      "    ann_file='data/coco/annotations/annotation_test.json',\n",
      "    metric='bbox',\n",
      "    format_only=False,\n",
      "    backend_args=None)\n",
      "test_evaluator = dict(\n",
      "    type='CocoMetric',\n",
      "    ann_file='data/coco/annotations/annotation_test.json',\n",
      "    metric='bbox',\n",
      "    format_only=False,\n",
      "    backend_args=None)\n",
      "train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=12, val_interval=3)\n",
      "val_cfg = dict(type='ValLoop')\n",
      "test_cfg = dict(type='TestLoop')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        type='LinearLR', start_factor=0.001, by_epoch=False, begin=0, end=500),\n",
      "    dict(\n",
      "        type='MultiStepLR',\n",
      "        begin=0,\n",
      "        end=12,\n",
      "        by_epoch=True,\n",
      "        milestones=[\n",
      "            8,\n",
      "            11,\n",
      "        ],\n",
      "        gamma=0.1),\n",
      "]\n",
      "optim_wrapper = dict(\n",
      "    type='OptimWrapper',\n",
      "    optimizer=dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001))\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "default_scope = 'mmdet'\n",
      "default_hooks = dict(\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    logger=dict(type='LoggerHook', interval=10),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    checkpoint=dict(type='CheckpointHook', interval=3),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
      "    dist_cfg=dict(backend='nccl'))\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(type='TensorboardVisBackend'),\n",
      "    ],\n",
      "    name='visualizer')\n",
      "log_processor = dict(type='LogProcessor', window_size=50, by_epoch=True)\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume = False\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Thermos bottle',\n",
      "        'Soymilk',\n",
      "        'Baby slippers',\n",
      "        'Makeup tools',\n",
      "        'Adult milk powder',\n",
      "        'Red wine',\n",
      "        'Toothpaste',\n",
      "        'Pot shovel',\n",
      "        'Rubber ball',\n",
      "        'Rise',\n",
      "        'Stool',\n",
      "        'Vinegar',\n",
      "        'Children Socks',\n",
      "        'Shampoo',\n",
      "        'Cake',\n",
      "        'Pen',\n",
      "        'Flour',\n",
      "        'Sesame paste',\n",
      "        'Dried meat',\n",
      "        'Baby diapers',\n",
      "        'Jacket',\n",
      "        'Herbal tea',\n",
      "        'Mouth wash',\n",
      "        'Care Kit',\n",
      "        'Baby Toys',\n",
      "        'Quick-frozen Wonton',\n",
      "        'Quick-frozen Tangyuan',\n",
      "        'Electric Hot pot',\n",
      "        'Electric steaming pan',\n",
      "        'Electric kettle',\n",
      "        'Sports cup',\n",
      "        'Quick-frozen dumplings',\n",
      "        'Can',\n",
      "        'Air conditioner',\n",
      "        'Instant noodles',\n",
      "        'Baby washing and nursing supplie',\n",
      "        'Socket',\n",
      "        'Potato chips',\n",
      "        'Disposable bag',\n",
      "        'Adult shoes',\n",
      "        'Football',\n",
      "        'Hair drier',\n",
      "        'Chopping block',\n",
      "        'Lingerie',\n",
      "        'Mug',\n",
      "        'Soup ladle',\n",
      "        'Children hats',\n",
      "        'Lotus root flour',\n",
      "        'Fish tofu',\n",
      "        'Electric iron',\n",
      "        'Ice cream',\n",
      "        'Bath lotion',\n",
      "        'Juicer',\n",
      "        'Tea beverage',\n",
      "        'Dinner plate',\n",
      "        'Notebook',\n",
      "        'Facial Cleanser',\n",
      "        'Biscuits',\n",
      "        'Chewing gum',\n",
      "        'Mixed congee',\n",
      "        'Facial mask',\n",
      "        'Bowl',\n",
      "        'Soybean Milk machine',\n",
      "        'Men underwear',\n",
      "        'Dairy',\n",
      "        'Hair gel',\n",
      "        'Tea',\n",
      "        'Storage bottle',\n",
      "        'Spoon',\n",
      "        'Baby milk powder',\n",
      "        'Sauce',\n",
      "        'Electric fan',\n",
      "        'Dried beans',\n",
      "        'Disposable cups',\n",
      "        'Draw bar box',\n",
      "        'Cooking wine',\n",
      "        'Pencil case',\n",
      "        'Carbonated drinks',\n",
      "        'Adult Diapers',\n",
      "        'Soy sauce',\n",
      "        'Desk lamp',\n",
      "        'Electromagnetic furnace',\n",
      "        'Badminton',\n",
      "        'Coffee',\n",
      "        'Air conditioning fan',\n",
      "        'Tampon',\n",
      "        'Children Toys',\n",
      "        'Children underwear',\n",
      "        'Knives',\n",
      "        'Pasta',\n",
      "        'Microwave Oven',\n",
      "        'Hair conditioner',\n",
      "        'Ginger Tea',\n",
      "        'Baby Furniture',\n",
      "        'Forks',\n",
      "        'Pie',\n",
      "        'Television',\n",
      "        'Baby tableware',\n",
      "        'Skate',\n",
      "        'Oats',\n",
      "        'Cotton swab',\n",
      "        'Storage box',\n",
      "        'Noodle',\n",
      "        'Razor',\n",
      "        'Refrigerator',\n",
      "        'Toothbrush',\n",
      "        'Chocolates',\n",
      "        'Adult socks',\n",
      "        'Knapsack',\n",
      "        'Sour Plum Soup',\n",
      "        'Cutter',\n",
      "        'Band aid',\n",
      "        'Rice cooker',\n",
      "        'Cocktail',\n",
      "        'Skin care set',\n",
      "        'Walnut powder',\n",
      "        'Liquor and Spirits',\n",
      "        'Emulsion',\n",
      "        'Soap',\n",
      "        'Hair dye',\n",
      "        'Fresh-keeping film',\n",
      "        'Baby handkerchiefs ',\n",
      "        'Children shoes',\n",
      "        'Washing machine',\n",
      "        'Chopsticks',\n",
      "        'Guozhen',\n",
      "        'Trousers',\n",
      "        'Adult hat',\n",
      "        'Trash',\n",
      "        'Bedding set',\n",
      "        'Basin',\n",
      "        'Electric frying pan',\n",
      "        'Food box',\n",
      "        'Dried fish',\n",
      "        'Baby carriage',\n",
      "        'Hot strips',\n",
      "        'Basketball',\n",
      "        'Comb',\n",
      "        'Coat hanger',\n",
      "    ))\n",
      "work_dir = './tutorial_exps'\n",
      "\n",
      "07/16 21:04:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "07/16 21:04:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    }
   ],
   "source": [
    "from mmengine.runner import Runner\n",
    "\n",
    "# build the runner from config\n",
    "runner = Runner.from_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/16 21:12:29 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - init_weights of CascadeRCNN has been called more than once.\n",
      "07/16 21:12:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /Users/nuthankumar/Data/Codes/Locount/Locount/raw/Locount/tutorial_exps.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m runner\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/runner.py:1735\u001b[0m, in \u001b[0;36mRunner.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1731\u001b[0m \u001b[39m# Maybe compile the model according to options in self.cfg.compile\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[39m# This must be called **AFTER** model has been wrapped.\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_compile(\u001b[39m'\u001b[39m\u001b[39mtrain_step\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1735\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_loop\u001b[39m.\u001b[39;49mrun()  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m   1736\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_hook(\u001b[39m'\u001b[39m\u001b[39mafter_run\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1737\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/loops.py:96\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunner\u001b[39m.\u001b[39mcall_hook(\u001b[39m'\u001b[39m\u001b[39mbefore_train\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epoch \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_epochs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_epoch()\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decide_current_val_interval()\n\u001b[1;32m     99\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunner\u001b[39m.\u001b[39mval_loop \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    100\u001b[0m             \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epoch \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_begin\n\u001b[1;32m    101\u001b[0m             \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epoch \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/loops.py:112\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunner\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m    111\u001b[0m \u001b[39mfor\u001b[39;00m idx, data_batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader):\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_iter(idx, data_batch)\n\u001b[1;32m    114\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunner\u001b[39m.\u001b[39mcall_hook(\u001b[39m'\u001b[39m\u001b[39mafter_train_epoch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epoch \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/loops.py:128\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run_iter\u001b[0;34m(self, idx, data_batch)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunner\u001b[39m.\u001b[39mcall_hook(\n\u001b[1;32m    124\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbefore_train_iter\u001b[39m\u001b[39m'\u001b[39m, batch_idx\u001b[39m=\u001b[39midx, data_batch\u001b[39m=\u001b[39mdata_batch)\n\u001b[1;32m    125\u001b[0m \u001b[39m# Enable gradient accumulation mode and avoid unnecessary gradient\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m# synchronization during gradient accumulation process.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39m# outputs should be a dict of loss.\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunner\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtrain_step(\n\u001b[1;32m    129\u001b[0m     data_batch, optim_wrapper\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunner\u001b[39m.\u001b[39;49moptim_wrapper)\n\u001b[1;32m    131\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunner\u001b[39m.\u001b[39mcall_hook(\n\u001b[1;32m    132\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mafter_train_iter\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    133\u001b[0m     batch_idx\u001b[39m=\u001b[39midx,\n\u001b[1;32m    134\u001b[0m     data_batch\u001b[39m=\u001b[39mdata_batch,\n\u001b[1;32m    135\u001b[0m     outputs\u001b[39m=\u001b[39moutputs)\n\u001b[1;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py:114\u001b[0m, in \u001b[0;36mBaseModel.train_step\u001b[0;34m(self, data, optim_wrapper)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m optim_wrapper\u001b[39m.\u001b[39moptim_context(\u001b[39mself\u001b[39m):\n\u001b[1;32m    113\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_preprocessor(data, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 114\u001b[0m     losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_forward(data, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m'\u001b[39;49m)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    115\u001b[0m parsed_losses, log_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_losses(losses)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    116\u001b[0m optim_wrapper\u001b[39m.\u001b[39mupdate_params(parsed_losses)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py:340\u001b[0m, in \u001b[0;36mBaseModel._run_forward\u001b[0;34m(self, data, mode)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Unpacks data for :meth:`forward`\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \n\u001b[1;32m    332\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39m    dict or list: Results of training or testing mode.\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m--> 340\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdata, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[1;32m    341\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    342\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(\u001b[39m*\u001b[39mdata, mode\u001b[39m=\u001b[39mmode)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Data/Codes/Locount/Locount/raw/Locount/mmdet/models/detectors/base.py:92\u001b[0m, in \u001b[0;36mBaseDetector.forward\u001b[0;34m(self, inputs, data_samples, mode)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"The unified entry for a forward process in both training and test.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[39mThe method should accept three modes: \"tensor\", \"predict\" and \"loss\":\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39m    - If ``mode=\"loss\"``, return a dict of tensor.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(inputs, data_samples)\n\u001b[1;32m     93\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     94\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(inputs, data_samples)\n",
      "File \u001b[0;32m~/Data/Codes/Locount/Locount/raw/Locount/mmdet/models/detectors/two_stage.py:174\u001b[0m, in \u001b[0;36mTwoStageDetector.loss\u001b[0;34m(self, batch_inputs, batch_data_samples)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mfor\u001b[39;00m data_sample \u001b[39min\u001b[39;00m rpn_data_samples:\n\u001b[1;32m    171\u001b[0m     data_sample\u001b[39m.\u001b[39mgt_instances\u001b[39m.\u001b[39mlabels \u001b[39m=\u001b[39m \\\n\u001b[1;32m    172\u001b[0m         torch\u001b[39m.\u001b[39mzeros_like(data_sample\u001b[39m.\u001b[39mgt_instances\u001b[39m.\u001b[39mlabels)\n\u001b[0;32m--> 174\u001b[0m rpn_losses, rpn_results_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrpn_head\u001b[39m.\u001b[39;49mloss_and_predict(\n\u001b[1;32m    175\u001b[0m     x, rpn_data_samples, proposal_cfg\u001b[39m=\u001b[39;49mproposal_cfg)\n\u001b[1;32m    176\u001b[0m \u001b[39m# avoid get same name with roi_head loss\u001b[39;00m\n\u001b[1;32m    177\u001b[0m keys \u001b[39m=\u001b[39m rpn_losses\u001b[39m.\u001b[39mkeys()\n",
      "File \u001b[0;32m~/Data/Codes/Locount/Locount/raw/Locount/mmdet/models/dense_heads/base_dense_head.py:161\u001b[0m, in \u001b[0;36mBaseDenseHead.loss_and_predict\u001b[0;34m(self, x, batch_data_samples, proposal_cfg)\u001b[0m\n\u001b[1;32m    157\u001b[0m outputs \u001b[39m=\u001b[39m unpack_gt_instances(batch_data_samples)\n\u001b[1;32m    158\u001b[0m (batch_gt_instances, batch_gt_instances_ignore,\n\u001b[1;32m    159\u001b[0m  batch_img_metas) \u001b[39m=\u001b[39m outputs\n\u001b[0;32m--> 161\u001b[0m outs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(x)\n\u001b[1;32m    163\u001b[0m loss_inputs \u001b[39m=\u001b[39m outs \u001b[39m+\u001b[39m (batch_gt_instances, batch_img_metas,\n\u001b[1;32m    164\u001b[0m                       batch_gt_instances_ignore)\n\u001b[1;32m    165\u001b[0m losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_by_feat(\u001b[39m*\u001b[39mloss_inputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Data/Codes/Locount/Locount/raw/Locount/mmdet/models/dense_heads/anchor_head.py:162\u001b[0m, in \u001b[0;36mAnchorHead.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tuple[Tensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[Tensor]]:\n\u001b[1;32m    146\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Forward features from the upstream network.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \n\u001b[1;32m    148\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39m                is num_base_priors * 4.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m multi_apply(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_single, x)\n",
      "File \u001b[0;32m~/Data/Codes/Locount/Locount/raw/Locount/mmdet/models/utils/misc.py:219\u001b[0m, in \u001b[0;36mmulti_apply\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m pfunc \u001b[39m=\u001b[39m partial(func, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mif\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m func\n\u001b[1;32m    218\u001b[0m map_results \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(pfunc, \u001b[39m*\u001b[39margs)\n\u001b[0;32m--> 219\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlist\u001b[39m, \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49mmap_results)))\n",
      "File \u001b[0;32m~/Data/Codes/Locount/Locount/raw/Locount/mmdet/models/dense_heads/rpn_head.py:93\u001b[0m, in \u001b[0;36mRPNHead.forward_single\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_single\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tensor, Tensor]:\n\u001b[1;32m     81\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Forward feature of a single scale level.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39m                level, the channels number is num_base_priors * 4.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrpn_conv(x)\n\u001b[1;32m     94\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m     95\u001b[0m     rpn_cls_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrpn_cls(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
